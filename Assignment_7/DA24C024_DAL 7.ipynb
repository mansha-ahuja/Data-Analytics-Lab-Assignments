{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAL Assigment 7\n",
    "# DA24C024- Mansha Ahuja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing, preprocessing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "f1 = make_scorer(f1_score , average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"C:/Users/Mansha/Downloads/aps_failure_training_set.csv\",skiprows=19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Columns: 171 entries, class to eg_000\n",
      "dtypes: int64(1), object(170)\n",
      "memory usage: 78.3+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #60000 X 171 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all the missing data is 'na' in string format. we will replace it to None so we can impute it later.\n",
    "data=data.replace('na',None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['class']=le.fit_transform(data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.fillna(data.median(), inplace = True) \n",
    "#Replacing missing data with median\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>76698</td>\n",
       "      <td>0</td>\n",
       "      <td>2130706438</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1240520</td>\n",
       "      <td>493384</td>\n",
       "      <td>721044</td>\n",
       "      <td>469792</td>\n",
       "      <td>339156</td>\n",
       "      <td>157956</td>\n",
       "      <td>73224</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>33058</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>421400</td>\n",
       "      <td>178064</td>\n",
       "      <td>293306</td>\n",
       "      <td>245416</td>\n",
       "      <td>133654</td>\n",
       "      <td>81140</td>\n",
       "      <td>97576</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>41040</td>\n",
       "      <td>0</td>\n",
       "      <td>228</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>277378</td>\n",
       "      <td>159812</td>\n",
       "      <td>423992</td>\n",
       "      <td>409564</td>\n",
       "      <td>320746</td>\n",
       "      <td>158022</td>\n",
       "      <td>95128</td>\n",
       "      <td>514</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>240</td>\n",
       "      <td>46</td>\n",
       "      <td>58</td>\n",
       "      <td>44</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>60874</td>\n",
       "      <td>0</td>\n",
       "      <td>1368</td>\n",
       "      <td>458</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>622012</td>\n",
       "      <td>229790</td>\n",
       "      <td>405298</td>\n",
       "      <td>347188</td>\n",
       "      <td>286954</td>\n",
       "      <td>311560</td>\n",
       "      <td>433954</td>\n",
       "      <td>1218</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   class  aa_000  ab_000      ac_000 ad_000 ae_000 af_000 ag_000 ag_001  \\\n",
       "0      0   76698       0  2130706438    280      0      0      0      0   \n",
       "1      0   33058       0           0  126.0      0      0      0      0   \n",
       "2      0   41040       0         228    100      0      0      0      0   \n",
       "3      0      12       0          70     66      0     10      0      0   \n",
       "4      0   60874       0        1368    458      0      0      0      0   \n",
       "\n",
       "  ag_002  ...   ee_002  ee_003  ee_004  ee_005  ee_006  ee_007  ee_008 ee_009  \\\n",
       "0      0  ...  1240520  493384  721044  469792  339156  157956   73224      0   \n",
       "1      0  ...   421400  178064  293306  245416  133654   81140   97576   1500   \n",
       "2      0  ...   277378  159812  423992  409564  320746  158022   95128    514   \n",
       "3      0  ...      240      46      58      44      10       0       0      0   \n",
       "4      0  ...   622012  229790  405298  347188  286954  311560  433954   1218   \n",
       "\n",
       "  ef_000 eg_000  \n",
       "0      0      0  \n",
       "1      0      0  \n",
       "2      0      0  \n",
       "3      4     32  \n",
       "4      0      0  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ab_000']=data['ab_000'].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = data.drop('class', axis=1)  # Feature columns\n",
    "y = data['class']  # Target column\n",
    "\n",
    "# Scaling the data to standard form\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled=pd.DataFrame(X_scaled)\n",
    "j=0\n",
    "for i in X:\n",
    "    X_scaled.rename(columns={j:i},inplace=True)\n",
    "    j=j+1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.119381</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>2.310224</td>\n",
       "      <td>-0.004085</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.693832</td>\n",
       "      <td>0.524393</td>\n",
       "      <td>0.239087</td>\n",
       "      <td>0.070072</td>\n",
       "      <td>0.008264</td>\n",
       "      <td>-0.107586</td>\n",
       "      <td>-0.143103</td>\n",
       "      <td>-0.175699</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.180697</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432859</td>\n",
       "      <td>-0.004089</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018901</td>\n",
       "      <td>-0.059135</td>\n",
       "      <td>-0.129021</td>\n",
       "      <td>-0.131171</td>\n",
       "      <td>-0.184975</td>\n",
       "      <td>-0.152281</td>\n",
       "      <td>-0.088650</td>\n",
       "      <td>-0.143927</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.125811</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432859</td>\n",
       "      <td>-0.004090</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.144217</td>\n",
       "      <td>-0.092912</td>\n",
       "      <td>-0.016553</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>-0.009047</td>\n",
       "      <td>-0.107547</td>\n",
       "      <td>-0.094124</td>\n",
       "      <td>-0.164812</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.407928</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432859</td>\n",
       "      <td>-0.004091</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.002669</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115223</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.385361</td>\n",
       "      <td>-0.388574</td>\n",
       "      <td>-0.381387</td>\n",
       "      <td>-0.351244</td>\n",
       "      <td>-0.310645</td>\n",
       "      <td>-0.199493</td>\n",
       "      <td>-0.306838</td>\n",
       "      <td>-0.175699</td>\n",
       "      <td>0.916833</td>\n",
       "      <td>3.685328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010572</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432857</td>\n",
       "      <td>-0.004080</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.155656</td>\n",
       "      <td>0.036588</td>\n",
       "      <td>-0.032641</td>\n",
       "      <td>-0.039892</td>\n",
       "      <td>-0.040823</td>\n",
       "      <td>-0.018211</td>\n",
       "      <td>0.663519</td>\n",
       "      <td>-0.149900</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59995</th>\n",
       "      <td>0.644064</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432858</td>\n",
       "      <td>-0.004088</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.112258</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483245</td>\n",
       "      <td>0.660411</td>\n",
       "      <td>0.729068</td>\n",
       "      <td>0.741356</td>\n",
       "      <td>0.648264</td>\n",
       "      <td>0.218138</td>\n",
       "      <td>1.702599</td>\n",
       "      <td>0.429824</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59996</th>\n",
       "      <td>-0.392291</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>2.310224</td>\n",
       "      <td>-0.004087</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376366</td>\n",
       "      <td>-0.376149</td>\n",
       "      <td>-0.363256</td>\n",
       "      <td>-0.289914</td>\n",
       "      <td>-0.310526</td>\n",
       "      <td>-0.199493</td>\n",
       "      <td>-0.306838</td>\n",
       "      <td>-0.175699</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59997</th>\n",
       "      <td>-0.407240</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>2.310224</td>\n",
       "      <td>-0.004092</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.384881</td>\n",
       "      <td>-0.387945</td>\n",
       "      <td>-0.381048</td>\n",
       "      <td>-0.351154</td>\n",
       "      <td>-0.310517</td>\n",
       "      <td>-0.197967</td>\n",
       "      <td>-0.306838</td>\n",
       "      <td>-0.175699</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59998</th>\n",
       "      <td>0.144095</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>2.310224</td>\n",
       "      <td>-0.004079</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222951</td>\n",
       "      <td>0.023382</td>\n",
       "      <td>-0.082487</td>\n",
       "      <td>-0.148832</td>\n",
       "      <td>-0.127816</td>\n",
       "      <td>-0.103447</td>\n",
       "      <td>1.487126</td>\n",
       "      <td>8.051473</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59999</th>\n",
       "      <td>-0.131435</td>\n",
       "      <td>-0.096307</td>\n",
       "      <td>-0.432858</td>\n",
       "      <td>-0.004075</td>\n",
       "      <td>-0.041322</td>\n",
       "      <td>-0.051358</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.02837</td>\n",
       "      <td>-0.056929</td>\n",
       "      <td>-0.115643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002659</td>\n",
       "      <td>-0.049631</td>\n",
       "      <td>-0.084924</td>\n",
       "      <td>-0.123411</td>\n",
       "      <td>-0.098941</td>\n",
       "      <td>-0.107383</td>\n",
       "      <td>0.074155</td>\n",
       "      <td>-0.172352</td>\n",
       "      <td>-0.020257</td>\n",
       "      <td>-0.023540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60000 rows Ã— 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         aa_000    ab_000    ac_000    ad_000    ae_000    af_000    ag_000  \\\n",
       "0      0.119381 -0.096307  2.310224 -0.004085 -0.041322 -0.051358 -0.010762   \n",
       "1     -0.180697 -0.096307 -0.432859 -0.004089 -0.041322 -0.051358 -0.010762   \n",
       "2     -0.125811 -0.096307 -0.432859 -0.004090 -0.041322 -0.051358 -0.010762   \n",
       "3     -0.407928 -0.096307 -0.432859 -0.004091 -0.041322 -0.002669 -0.010762   \n",
       "4      0.010572 -0.096307 -0.432857 -0.004080 -0.041322 -0.051358 -0.010762   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "59995  0.644064 -0.096307 -0.432858 -0.004088 -0.041322 -0.051358 -0.010762   \n",
       "59996 -0.392291 -0.096307  2.310224 -0.004087 -0.041322 -0.051358 -0.010762   \n",
       "59997 -0.407240 -0.096307  2.310224 -0.004092 -0.041322 -0.051358 -0.010762   \n",
       "59998  0.144095 -0.096307  2.310224 -0.004079 -0.041322 -0.051358 -0.010762   \n",
       "59999 -0.131435 -0.096307 -0.432858 -0.004075 -0.041322 -0.051358 -0.010762   \n",
       "\n",
       "        ag_001    ag_002    ag_003  ...    ee_002    ee_003    ee_004  \\\n",
       "0     -0.02837 -0.056929 -0.115643  ...  0.693832  0.524393  0.239087   \n",
       "1     -0.02837 -0.056929 -0.115643  ... -0.018901 -0.059135 -0.129021   \n",
       "2     -0.02837 -0.056929 -0.115643  ... -0.144217 -0.092912 -0.016553   \n",
       "3     -0.02837 -0.056929 -0.115223  ... -0.385361 -0.388574 -0.381387   \n",
       "4     -0.02837 -0.056929 -0.115643  ...  0.155656  0.036588 -0.032641   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "59995 -0.02837 -0.056929 -0.112258  ...  0.483245  0.660411  0.729068   \n",
       "59996 -0.02837 -0.056929 -0.115643  ... -0.376366 -0.376149 -0.363256   \n",
       "59997 -0.02837 -0.056929 -0.115643  ... -0.384881 -0.387945 -0.381048   \n",
       "59998 -0.02837 -0.056929 -0.115643  ...  0.222951  0.023382 -0.082487   \n",
       "59999 -0.02837 -0.056929 -0.115643  ... -0.002659 -0.049631 -0.084924   \n",
       "\n",
       "         ee_005    ee_006    ee_007    ee_008    ee_009    ef_000    eg_000  \n",
       "0      0.070072  0.008264 -0.107586 -0.143103 -0.175699 -0.020257 -0.023540  \n",
       "1     -0.131171 -0.184975 -0.152281 -0.088650 -0.143927 -0.020257 -0.023540  \n",
       "2      0.016053 -0.009047 -0.107547 -0.094124 -0.164812 -0.020257 -0.023540  \n",
       "3     -0.351244 -0.310645 -0.199493 -0.306838 -0.175699  0.916833  3.685328  \n",
       "4     -0.039892 -0.040823 -0.018211  0.663519 -0.149900 -0.020257 -0.023540  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "59995  0.741356  0.648264  0.218138  1.702599  0.429824 -0.020257 -0.023540  \n",
       "59996 -0.289914 -0.310526 -0.199493 -0.306838 -0.175699 -0.020257 -0.023540  \n",
       "59997 -0.351154 -0.310517 -0.197967 -0.306838 -0.175699 -0.020257 -0.023540  \n",
       "59998 -0.148832 -0.127816 -0.103447  1.487126  8.051473 -0.020257 -0.023540  \n",
       "59999 -0.123411 -0.098941 -0.107383  0.074155 -0.172352 -0.020257 -0.023540  \n",
       "\n",
       "[60000 rows x 170 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "#Splitting into training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying PCA to reduce dimensionality of the dataset (171 cols -> 15 cols)\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=15)\n",
    "\n",
    "X_train = pca.fit_transform(X_train)\n",
    "X_test = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.157191</td>\n",
       "      <td>0.147491</td>\n",
       "      <td>-0.240938</td>\n",
       "      <td>1.009317</td>\n",
       "      <td>0.095782</td>\n",
       "      <td>-0.281785</td>\n",
       "      <td>-0.018146</td>\n",
       "      <td>0.309538</td>\n",
       "      <td>0.444453</td>\n",
       "      <td>-1.027954</td>\n",
       "      <td>-0.664358</td>\n",
       "      <td>-0.375053</td>\n",
       "      <td>0.092209</td>\n",
       "      <td>0.076550</td>\n",
       "      <td>-0.011503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-3.182998</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>-0.237852</td>\n",
       "      <td>1.030161</td>\n",
       "      <td>0.099028</td>\n",
       "      <td>-0.280221</td>\n",
       "      <td>-0.019771</td>\n",
       "      <td>0.322503</td>\n",
       "      <td>0.475563</td>\n",
       "      <td>-1.112315</td>\n",
       "      <td>-0.776668</td>\n",
       "      <td>-0.451536</td>\n",
       "      <td>0.113747</td>\n",
       "      <td>0.103053</td>\n",
       "      <td>0.024140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-3.105980</td>\n",
       "      <td>0.283037</td>\n",
       "      <td>-0.260968</td>\n",
       "      <td>0.956684</td>\n",
       "      <td>0.163922</td>\n",
       "      <td>-0.275342</td>\n",
       "      <td>-0.020550</td>\n",
       "      <td>0.312773</td>\n",
       "      <td>0.297919</td>\n",
       "      <td>-0.962648</td>\n",
       "      <td>-0.784711</td>\n",
       "      <td>-0.528079</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>0.128629</td>\n",
       "      <td>0.060734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.889271</td>\n",
       "      <td>-0.265283</td>\n",
       "      <td>-0.841762</td>\n",
       "      <td>-0.116937</td>\n",
       "      <td>-0.090044</td>\n",
       "      <td>0.438061</td>\n",
       "      <td>-0.013827</td>\n",
       "      <td>-0.262152</td>\n",
       "      <td>0.064045</td>\n",
       "      <td>0.233263</td>\n",
       "      <td>-0.181658</td>\n",
       "      <td>0.065911</td>\n",
       "      <td>-0.010019</td>\n",
       "      <td>0.195867</td>\n",
       "      <td>-0.022233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.168067</td>\n",
       "      <td>-0.684581</td>\n",
       "      <td>-0.926181</td>\n",
       "      <td>0.170696</td>\n",
       "      <td>-0.502622</td>\n",
       "      <td>0.427632</td>\n",
       "      <td>-0.011866</td>\n",
       "      <td>-0.077737</td>\n",
       "      <td>0.271432</td>\n",
       "      <td>-0.642372</td>\n",
       "      <td>-0.622726</td>\n",
       "      <td>-0.262499</td>\n",
       "      <td>0.192551</td>\n",
       "      <td>0.141720</td>\n",
       "      <td>-0.006799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47995</th>\n",
       "      <td>0.763917</td>\n",
       "      <td>-0.411676</td>\n",
       "      <td>-0.056035</td>\n",
       "      <td>-0.780732</td>\n",
       "      <td>1.668225</td>\n",
       "      <td>-0.854618</td>\n",
       "      <td>-0.017730</td>\n",
       "      <td>-0.044731</td>\n",
       "      <td>-0.010094</td>\n",
       "      <td>0.499272</td>\n",
       "      <td>-0.380563</td>\n",
       "      <td>-0.269064</td>\n",
       "      <td>0.318868</td>\n",
       "      <td>0.194893</td>\n",
       "      <td>0.062891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47996</th>\n",
       "      <td>-3.184922</td>\n",
       "      <td>-0.917797</td>\n",
       "      <td>10.988673</td>\n",
       "      <td>-2.463721</td>\n",
       "      <td>-0.277622</td>\n",
       "      <td>0.855850</td>\n",
       "      <td>0.002981</td>\n",
       "      <td>0.306987</td>\n",
       "      <td>0.154274</td>\n",
       "      <td>-0.784555</td>\n",
       "      <td>-0.918543</td>\n",
       "      <td>-0.565920</td>\n",
       "      <td>0.166663</td>\n",
       "      <td>0.106409</td>\n",
       "      <td>0.343206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47997</th>\n",
       "      <td>-0.779318</td>\n",
       "      <td>-0.281135</td>\n",
       "      <td>-0.580480</td>\n",
       "      <td>-0.053040</td>\n",
       "      <td>-0.003134</td>\n",
       "      <td>0.043001</td>\n",
       "      <td>-0.007464</td>\n",
       "      <td>-0.195204</td>\n",
       "      <td>-0.182737</td>\n",
       "      <td>0.276724</td>\n",
       "      <td>0.211310</td>\n",
       "      <td>0.139402</td>\n",
       "      <td>-0.184856</td>\n",
       "      <td>0.139934</td>\n",
       "      <td>-0.064676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47998</th>\n",
       "      <td>-3.147847</td>\n",
       "      <td>0.159167</td>\n",
       "      <td>-0.243313</td>\n",
       "      <td>1.009574</td>\n",
       "      <td>0.119556</td>\n",
       "      <td>-0.267694</td>\n",
       "      <td>-0.019300</td>\n",
       "      <td>0.332555</td>\n",
       "      <td>0.465815</td>\n",
       "      <td>-1.081504</td>\n",
       "      <td>-0.739139</td>\n",
       "      <td>-0.431422</td>\n",
       "      <td>0.101882</td>\n",
       "      <td>0.083147</td>\n",
       "      <td>0.016772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47999</th>\n",
       "      <td>-1.064435</td>\n",
       "      <td>-0.479343</td>\n",
       "      <td>-0.759060</td>\n",
       "      <td>-0.220048</td>\n",
       "      <td>0.143570</td>\n",
       "      <td>0.089961</td>\n",
       "      <td>0.007004</td>\n",
       "      <td>-0.597952</td>\n",
       "      <td>-0.965034</td>\n",
       "      <td>2.025834</td>\n",
       "      <td>1.700135</td>\n",
       "      <td>1.148846</td>\n",
       "      <td>-0.510917</td>\n",
       "      <td>-0.141033</td>\n",
       "      <td>-0.103024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48000 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1          2         3         4         5         6   \\\n",
       "0     -3.157191  0.147491  -0.240938  1.009317  0.095782 -0.281785 -0.018146   \n",
       "1     -3.182998  0.151600  -0.237852  1.030161  0.099028 -0.280221 -0.019771   \n",
       "2     -3.105980  0.283037  -0.260968  0.956684  0.163922 -0.275342 -0.020550   \n",
       "3     -0.889271 -0.265283  -0.841762 -0.116937 -0.090044  0.438061 -0.013827   \n",
       "4     -0.168067 -0.684581  -0.926181  0.170696 -0.502622  0.427632 -0.011866   \n",
       "...         ...       ...        ...       ...       ...       ...       ...   \n",
       "47995  0.763917 -0.411676  -0.056035 -0.780732  1.668225 -0.854618 -0.017730   \n",
       "47996 -3.184922 -0.917797  10.988673 -2.463721 -0.277622  0.855850  0.002981   \n",
       "47997 -0.779318 -0.281135  -0.580480 -0.053040 -0.003134  0.043001 -0.007464   \n",
       "47998 -3.147847  0.159167  -0.243313  1.009574  0.119556 -0.267694 -0.019300   \n",
       "47999 -1.064435 -0.479343  -0.759060 -0.220048  0.143570  0.089961  0.007004   \n",
       "\n",
       "             7         8         9         10        11        12        13  \\\n",
       "0      0.309538  0.444453 -1.027954 -0.664358 -0.375053  0.092209  0.076550   \n",
       "1      0.322503  0.475563 -1.112315 -0.776668 -0.451536  0.113747  0.103053   \n",
       "2      0.312773  0.297919 -0.962648 -0.784711 -0.528079  0.031441  0.128629   \n",
       "3     -0.262152  0.064045  0.233263 -0.181658  0.065911 -0.010019  0.195867   \n",
       "4     -0.077737  0.271432 -0.642372 -0.622726 -0.262499  0.192551  0.141720   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "47995 -0.044731 -0.010094  0.499272 -0.380563 -0.269064  0.318868  0.194893   \n",
       "47996  0.306987  0.154274 -0.784555 -0.918543 -0.565920  0.166663  0.106409   \n",
       "47997 -0.195204 -0.182737  0.276724  0.211310  0.139402 -0.184856  0.139934   \n",
       "47998  0.332555  0.465815 -1.081504 -0.739139 -0.431422  0.101882  0.083147   \n",
       "47999 -0.597952 -0.965034  2.025834  1.700135  1.148846 -0.510917 -0.141033   \n",
       "\n",
       "             14  \n",
       "0     -0.011503  \n",
       "1      0.024140  \n",
       "2      0.060734  \n",
       "3     -0.022233  \n",
       "4     -0.006799  \n",
       "...         ...  \n",
       "47995  0.062891  \n",
       "47996  0.343206  \n",
       "47997 -0.064676  \n",
       "47998  0.016772  \n",
       "47999 -0.103024  \n",
       "\n",
       "[48000 rows x 15 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pd.DataFrame(X_train))\n",
    "#new scaled df after PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for SVC\n",
    "param_grid_svc = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [0.1, 1, 10],                      \n",
    "    'gamma': ['scale', 'auto'],                \n",
    "}\n",
    "\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={&#x27;C&#x27;: [0.1, 1, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
       "                         &#x27;kernel&#x27;: [&#x27;rbf&#x27;]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10], 'gamma': ['scale', 'auto'],\n",
       "                         'kernel': ['rbf']})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_model = GridSearchCV(svc, param_grid_svc, cv=5)\n",
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and evaluation\n",
    "print(\"Best SVC Params:\", svc_model.best_params_)\n",
    "svc_best = svc_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=10)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=10)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best.fit(X_train,y_train)\n",
    "pred_svc=svc_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(pred_svc,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score SVC 0.6721311475409836\n"
     ]
    }
   ],
   "source": [
    "svc_1=f1_score(y_test,pred_svc)\n",
    "print(\"F1 score SVC\", svc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for Logistic Regression\n",
    "\n",
    "param_grid_lr= {\n",
    "    'C': [0.01, 0.1, 1, 10], \n",
    "    'penalty': ['l1', 'l2'], \n",
    "    'solver': ['liblinear','saga','lbfgs']\n",
    "}\n",
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;background-color: white;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10], &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;liblinear&#x27;, &#x27;saga&#x27;, &#x27;lbfgs&#x27;]},\n",
       "             scoring=make_scorer(f1_score, average=macro))</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10], 'penalty': ['l1', 'l2'],\n",
       "                         'solver': ['liblinear', 'saga', 'lbfgs']},\n",
       "             scoring=make_scorer(f1_score, average=macro))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_model = GridSearchCV(lr, param_grid_lr, cv=5, scoring=f1)\n",
    "lr_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'C': 10, 'penalty': 'l2', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Logistic Regression Params:\", lr_model.best_params_)\n",
    "lr_best = lr_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Mansha\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=10, solver=&#x27;saga&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=10, solver='saga')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_lr=lr_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9883333333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(pred_lr,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score LR:  0.5906432748538012\n"
     ]
    }
   ],
   "source": [
    "lr_1=f1_score(y_test,pred_lr)\n",
    "print(\"F1 score LR: \",lr_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameter grid for Decision Tree\n",
    "\n",
    "param_grid_dt = {\n",
    "    'max_depth': [3, 5, 10], \n",
    "    'min_samples_split': [2, 5, 10], \n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "dec_tree=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = GridSearchCV(dec_tree, param_grid_dt, cv=5, scoring=f1)\n",
    "dt_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree Params: {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 5}\n"
     ]
    }
   ],
   "source": [
    "# Best parameters and evaluation\n",
    "print(\"Best Decision Tree Params:\", dt_model.best_params_)\n",
    "dt_best = dt_model.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" checked><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, min_samples_leaf=4, min_samples_split=5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_best.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dt=dt_best.predict(X_test)\n",
    "accuracy_score(pred_dt,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score DT:  0.573816155988858\n"
     ]
    }
   ],
   "source": [
    "dt_1=f1_score(y_test,pred_dt)\n",
    "print(\"F1 score DT: \", dt_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2a: UnderSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn==1.2.2 in c:\\users\\mansha\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\mansha\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\mansha\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\mansha\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\mansha\\anaconda3\\lib\\site-packages (from scikit-learn==1.2.2) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import imblearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "from imblearn.under_sampling import RandomUnderSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 1.2.2. \n"
     ]
    }
   ],
   "source": [
    "print('The scikit-learn version is {}. '. format(sklearn. __version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using undersampling to handle class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled_rus, y_resampled_rus = rus.fit_resample(X_train, y_train)\n",
    "skf = StratifiedKFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "F1 score after undersampling for SVC 0.6431587712260266\n"
     ]
    }
   ],
   "source": [
    "svc_under= GridSearchCV(svc, param_grid=param_grid_svc, cv=skf, scoring=f1) #running gridsearch on undersampled data\n",
    "svc_under.fit(X_resampled_rus, y_resampled_rus)\n",
    "print(\"Best SVC Params:\", svc_model.best_params_)\n",
    "svc_best_resampled = svc_under.best_estimator_\n",
    "pred_svc_rus=svc_best_resampled.predict(X_test)\n",
    "y_train_svc=svc_best_resampled.predict(X_resampled_rus)\n",
    "svc_2=f1_score(y_test,pred_svc_rus, average='macro')\n",
    "print(\"F1 score after undersampling for SVC\",f1_score(y_test,pred_svc_rus, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logicstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR Params: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n"
     ]
    }
   ],
   "source": [
    "lr_under= GridSearchCV(lr, param_grid=param_grid_lr, cv=skf, scoring=f1)\n",
    "lr_under.fit(X_resampled_rus, y_resampled_rus)\n",
    "print(\"Best LR Params:\", lr_model.best_params_)\n",
    "lr_best_resampled = lr_under.best_estimator_\n",
    "pred_lr_rus=lr_best_resampled.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for LR after undersampling 0.6849275720047749\n"
     ]
    }
   ],
   "source": [
    "lr_2=f1_score(y_test,pred_lr_rus, average='macro')\n",
    "print(\"F1 score for LR after undersampling\",f1_score(y_test,pred_lr_rus, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT Params: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 10}\n",
      "F1 score after undersampling for DT 0.6431587712260266\n"
     ]
    }
   ],
   "source": [
    "dt_under= GridSearchCV(dec_tree, param_grid=param_grid_dt, cv=skf, scoring=f1)\n",
    "dt_under.fit(X_resampled_rus, y_resampled_rus)\n",
    "# Best parameters and evaluation\n",
    "print(\"Best DT Params:\", dt_under.best_params_)\n",
    "dt_best_resampled = dt_under.best_estimator_\n",
    "pred_dt_rus=svc_best_resampled.predict(X_test)\n",
    "dt_2=f1_score(y_test,pred_dt_rus, average='macro')\n",
    "print(\"F1 score after undersampling for DT\",f1_score(y_test,pred_dt_rus, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2/3 cases, the F1 score for undersampled data is better than that of baselines classifiers. For SVC, it is slightly lower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2b: Using Class Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using balanced class weights for classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_w=LogisticRegression(class_weight='balanced')\n",
    "dt_w=DecisionTreeClassifier(class_weight='balanced')\n",
    "svc_w=SVC(class_weight='balanced')\n",
    "#Initializing classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVC Params: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "F1 score after using class weights in SVC 0.7529515472211461\n"
     ]
    }
   ],
   "source": [
    "svc_cw= GridSearchCV(svc_w, param_grid=param_grid_svc, cv=5, scoring=f1)\n",
    "svc_cw.fit(X_train, y_train)\n",
    "print(\"Best SVC Params:\", svc_cw.best_params_)\n",
    "svc_best_cw = svc_cw.best_estimator_\n",
    "pred_svc_cw=svc_best_cw.predict(X_test)\n",
    "svc_3=f1_score(y_test,pred_svc_cw,average='macro')\n",
    "print(\"F1 score after using class weights in SVC\" ,f1_score(y_test,pred_svc_cw,average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR Params: {'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "F1 score after using class weights LR 0.7274727973131795\n"
     ]
    }
   ],
   "source": [
    "lr_cw= GridSearchCV(lr_w, param_grid=param_grid_lr, cv=skf, scoring=f1)\n",
    "lr_cw.fit(X_train, y_train)\n",
    "# Best parameters and evaluation\n",
    "print(\"Best LR Params:\", lr_cw.best_params_)\n",
    "lr_best_cw = lr_cw.best_estimator_\n",
    "pred_lr_cw=lr_best_cw.predict(X_test)\n",
    "lr_3=f1_score(y_test,pred_lr_cw,average='macro')\n",
    "print(\"F1 score after using class weights LR\" ,f1_score(y_test,pred_lr_cw,average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT Params: {'min_samples_leaf': 2, 'min_samples_split': 5}\n",
      "F1 score after undersampling for DT 0.7673626652446157\n"
     ]
    }
   ],
   "source": [
    "dt_cw= GridSearchCV(dt_w, param_grid=param_grid_dt, cv=skf, scoring=f1)\n",
    "dt_cw.fit(X_train, y_train)\n",
    "print(\"Best DT Params:\", dt_cw.best_params_)\n",
    "dt_best_cw = dt_cw.best_estimator_\n",
    "pred_dt_cw=dt_best_cw.predict(X_test)\n",
    "dt_3=f1_score(y_test,pred_dt_cw,average='macro')\n",
    "print(\"F1 score after undersampling for DT\",f1_score(y_test,pred_dt_cw,average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2(c) : Using Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "sample_weights = compute_sample_weight(class_weight='balanced', y=y_train)\n",
    "#creating sample weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for SVC with sample weights: 0.7559294195738384\n"
     ]
    }
   ],
   "source": [
    "# For SVM with sample weights\n",
    "svc_sw = SVC()\n",
    "svc_sw.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "pred_svc_sw = svc_sw.predict(X_test)\n",
    "svc_4=f1_score(y_test, pred_svc_sw, average='macro')\n",
    "print(\"F1 score for SVC with sample weights:\", f1_score(y_test, pred_svc_sw, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for LR with sample weights: 0.7274727973131795\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# For Logistic Regression with sample weights\n",
    "lr_sw = LogisticRegression()\n",
    "lr_sw.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "pred_lr_sw = lr_sw.predict(X_test)\n",
    "lr_4=f1_score(y_test, pred_lr_sw, average='macro')\n",
    "print(\"F1 score for LR with sample weights:\", f1_score(y_test, pred_lr_sw, average='macro'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decison Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Decision Tree with sample weights: 0.7847301951779564\n"
     ]
    }
   ],
   "source": [
    "# For Decision Tree with sample weights\n",
    "dt_sw = DecisionTreeClassifier()\n",
    "dt_sw.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "pred_dt_sw = dt_sw.predict(X_test)\n",
    "dt_4=f1_score(y_test, pred_dt_sw, average='macro')\n",
    "print(\"F1 score for Decision Tree with sample weights:\", f1_score(y_test, pred_dt_sw, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2(d) : Creative ideas to address the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use ensembles to adrdess class imblanace i.e. using Random Forest instead of Decision Tree and Bagging Technique for SVC and Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Bagging SVC: 0.815142332393558\n"
     ]
    }
   ],
   "source": [
    "# SVC with Bagging\n",
    "bagging_svc = BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=42)\n",
    "bagging_svc.fit(X_train, y_train)\n",
    "pred_svc_bagging = bagging_svc.predict(X_test)\n",
    "svc_5=f1_score(y_test, pred_svc_bagging, average='macro')\n",
    "print(\"F1 score for Bagging SVC:\", f1_score(y_test, pred_svc_bagging, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score for Bagging Logistic Regression: 0.7958909941274923\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with Bagging\n",
    "bagging_lr = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10, random_state=42)\n",
    "bagging_lr.fit(X_train, y_train)\n",
    "pred_lr_bagging = bagging_lr.predict(X_test)\n",
    "lr_5=f1_score(y_test, pred_lr_bagging, average='macro')\n",
    "print(\"F1 score for Bagging Logistic Regression:\", f1_score(y_test, pred_lr_bagging, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score using Random Forest: 0.8523597883597883\n"
     ]
    }
   ],
   "source": [
    "#Random Forest (ensemble decision Tree)\n",
    "rfc=RandomForestClassifier()\n",
    "rfc.fit(X_train,y_train)\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "dt_5=f1_score(y_test, rfc_predict, average='macro')\n",
    "print('F1 score using Random Forest:',f1_score(y_test, rfc_predict, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------FINAL RESULTS FOR THE TASKS------------------------------\n",
      "\n",
      " Baseline Models \n",
      " SVC:  0.6721311475409836 \tLogistic Regression:  0.5906432748538012 \tDecision Tree:  0.573816155988858\n",
      "\n",
      " Using Under Sampling \n",
      " SVC:  0.6431587712260266 \tLogistic Regression:  0.6849275720047749 \tDecision Tree:  0.6431587712260266\n",
      "\n",
      " Using Class Weights \n",
      " SVC:  0.7529515472211461 \tLogistic Regression:  0.7274727973131795 \tDecision Tree:  0.7673626652446157\n",
      "\n",
      " Using Sample Weights \n",
      " SVC:  0.7559294195738384 \tLogistic Regression:  0.7274727973131795 \tDecision Tree:  0.7847301951779564\n",
      "\n",
      " Using Ensembles/Bagging \n",
      " SVC:  0.815142332393558 \tLogistic Regression:  0.7958909941274923 \tDT/ Random Forest:  0.8523597883597883\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n------------------------------FINAL RESULTS FOR THE TASKS------------------------------\")\n",
    "print(\"\\n Baseline Models \\n\", \"SVC: \", svc_1, \"\\tLogistic Regression: \",lr_1, \"\\tDecision Tree: \", dt_1)\n",
    "print(\"\\n Using Under Sampling \\n\", \"SVC: \", svc_2, \"\\tLogistic Regression: \",lr_2, \"\\tDecision Tree: \", dt_2)\n",
    "print(\"\\n Using Class Weights \\n\", \"SVC: \", svc_3, \"\\tLogistic Regression: \",lr_3, \"\\tDecision Tree: \", dt_3)\n",
    "print(\"\\n Using Sample Weights \\n\", \"SVC: \", svc_4, \"\\tLogistic Regression: \",lr_4, \"\\tDecision Tree: \", dt_4)\n",
    "print(\"\\n Using Ensembles/Bagging \\n\", \"SVC: \", svc_5, \"\\tLogistic Regression: \",lr_5, \"\\tDT/ Random Forest: \", dt_5)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So all methods used to tackle class imbalance in task 2 give better results than the baseline models. Overall, we get the best results by using ensembling mehods/bagging. Ensembling methods like bagging can handle class imbalance by creating multiple subsets of data through random sampling, which may include more minority class instances in some subsets thus leading to better performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
